{
  "projects": [
    {
      "id": "e-certificate",
      "type": "Web Platform",
      "title": "E-Certificate Issuance Web platform",
      "technologies": [
        "Vue",
        "TypeScript",
        "NodeJS",
        "MySQL",
        "Cloudinary",
        "Hostinger",
        "Vercel",
        "Tailwind CSS"
      ],
      "year": "March, 2025",
      "role": "Full stack Developer",
      "member": "2 Developers",
      "demoUrl": "#",
      "sourceUrl": "#",
      "designUrl": "#",
      "hiddenSections": ["Security", "Impact & Reflection"],
      "hideLinks": true,
      "topImage": "/assets/certificate-hero.png",
      "sections": {
        "product-overview": {
          "heading": "Digital Certificate Generation & Sharing System",
          "body": [
            "Developed an online certificate issuance system that allows students to instantly receive and share their certificates digitally.",
            "Each certificate includes a QR code, which redirects users to a public certificate verification page, enabling students to share verified certificates on platforms like LinkedIn, Facebook, and X (Twitter)."
          ],
          "image": "/assets/certificate-preview.png",
          "keyFeatures": [
            {
              "title": "Instant Generation",
              "description": "Client-side PDF rendering ensures zero server wait time."
            },
            {
              "title": "Verification",
              "description": "Each certificate includes a unique QR code linked to a persistent public URL."
            },
            {
              "title": "Social Sharing",
              "description": "Optimized Open Graph tags allow beautiful previews on platforms like Facebook and LinkedIn."
            },
            {
              "title": "Secure Storage",
              "description": "Digital assets are stored in Cloudinary, while metadata is secured in MySQL."
            }
          ]
        },
        "system-design": {
          "body": [],
          "image": "/assets/certificate-issuance-platform.png",
          "numberedItems": [
            {
              "title": "Server Orchestration (Express.js)",
              "description": "The server acts as a secure middleware. It receives the payload and splits the data stream:",
              "subPoints": [
                "Assets: The image is uploaded to Cloudinary via upload streams.",
                "Metadata: Essential records (Student ID, Issue Date, Image URL) are stored in MySQL."
              ]
            },
            {
              "title": "Dynamic Delivery & Verification",
              "description": "",
              "subPoints": [
                "Public Access: Each certificate gets a unique, verifiable URL (/api/certificates/:id.jpg).",
                "QR Verification: Scanning the QR code leads to a persistent verification page hosted on the client."
              ]
            },
            {
              "title": "Social Sharing Optimization",
              "description": "A dedicated server-side route handles Open Graph (OG) tag injection. This ensures that crawlers from LinkedIn, Facebook, and X (Twitter) can correctly fetch and display the certificate preview image, bridging the gap between SPA architecture and social bots."
            }
          ],
          "heading": "1. Tech stack",
          "techStackBody": [
            "Why Vue3?:",
            "Optimized for Dashboard UX (SPA Architecture) The primary function of this application is an Admin Dashboard for school officers. Unlike public content sites, admin panels require a snappy, app-like experience. Vue's SPA architecture ensures that once the initial application is loaded, all subsequent operations are extremely fast with zero page reloads. This performance is ideal for the highly interactive UI required in a management environment.",
            "High Productivity with Forms (Two-Way Binding) Certificate generation involves complex data entry and validation. Vue's two-way data binding (v-model) significantly reduces boilerplate code compared to React's one-way data flow. This allowed me to build and iterate on the complex form logic much faster.",
            "Pragmatic Problem Solving (Avoiding Over-engineering) While frameworks like Next.js offer built-in SEO solutions, migrating the entire application just for the \"Social Media Share\" feature would have been over-engineering. Instead, I maintained the agility of Vue for the frontend and implemented a targeted backend solution (Express) for the specific OG tag requirement, balancing development efficiency with functional requirements."
          ],
          "techStackSections": [
            {
              "title": "Frontend",
              "items": [
                "Framework: Vue 3 (Composition API) + TypeScript",
                "Build Tool: Vite",
                "Styling: Tailwind CSS, Tailwind Merge, Tailwind Animate",
                "Routing: Vue Router",
                "Form Handling: Zod, Vue Hook Form Resolver",
                "PDF / Certificate Rendering: PDF-lib, html2canvas, jsPDF",
                "Charts & Visualization: Chart.js, Vue Chart.js, Chart.js Plugin Datalabels, Recharts",
                "Utilities: VueUse, Date-fns, Axios, QRCode, Quill, Vue3-Toastify"
              ]
            },
            {
              "title": "Backend",
              "items": [
                "Runtime / Framework: Express.js (TypeScript)",
                "Database: MySQL",
                "File Uploads: Multer",
                "Cloud Storage: Cloudinary",
                "PDF/Image Conversion: Cloudinary upload streams",
                "Environment Management: dotenv",
                "CORS: cors (Cross-Origin Resource Sharing)"
              ]
            },
            {
              "title": "Development & Tooling",
              "items": [
                "Language: TypeScript",
                "Dev Tools: ts-node, tsx, Vite, Vue TSC",
                "Version Control & CI/CD: GitHub Actions",
                "Deployment:",
                "Server: Vercel",
                "Client: Hostinger",
                "Media Storage: Cloudinary",
                "Legacy Data Source: WordPress (student info API integration)"
              ]
            }
          ]
        },
        "process": {
          "body": [],
          "image": "/assets/certificate-flowchart.png",
          "imageTitle": "End-to-End User Workflow",
          "imageBelowFirst": "/assets/architecture-diagram.png",
          "imageBelowFirstTitle": "Full-Stack Implementation Overview user journey map"
        },
        "constraints--trade-offs": {
          "body": [],
          "processBlocks": [
            {
              "title": "1. Blob-to-JPEG Conversion in a Serverless Environment",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "items": [
                    {
                      "title": "1-1. initial attempt: Converting PDF to JPEG using Poppler",
                      "body": "Converting PDF blobs to JPEG in a serverless environment (Vercel) was challenging. An initial attempt using the **Poppler** library, a C++ library for working with PDFs that Node.js bindings like `node-poppler` and `pdf2json` rely on, failed. This is because Vercel's serverless environment does not support libraries requiring native binaries (such as .so or .dll shared libraries) out of the box, making Poppler unsuitable for this specific setup."
                    },
                    {
                      "title": "1-2. second attempt: Rendering the certificate as styled HTML with Puppeteer",
                      "body": "A second attempt used CSS for the diploma layout and Puppeteer (a Node.js library for headless Chrome) to convert styled HTML to PDF. PDF generation worked but the rendered images appeared blurry and pixelated in the browser, making it unsuitable for production."
                    },
                    {
                      "title": "1-3. third attempt: Client-side PDF generation (pdf-lib + Cloudinary)",
                      "body": "The client could build the certificate as a PDF with pdf-lib, send Base64 to the Express API, and the server could upload to Cloudinary with format: 'jpg' (conversion handled there), avoiding native dependencies and Vercel limits. However, issuing certificates on the client is not acceptable from a security perspective, as the process could be tampered with."
                    }
                  ],
                  "imageSrc": "/assets/blob-to-jpeg-all-attempts-failed.png"
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "To overcome the limitations of the serverless runtime, I re-architected the generation and conversion pipeline to remove all native dependencies.",
                    "First, I replaced the native-dependent tools with pdf-lib, a pure JavaScript library, allowing me to generate PDFs directly within the Node.js environment without requiring OS-level binaries.",
                    "Second, for the PDF-to-JPEG conversion, I offloaded the heavy processing to the cloud. Instead of converting the file on the Vercel server, I implemented a stream upload to Cloudinary with a format: 'jpg' transformation parameter. This allowed the application to leverage Cloudinary's infrastructure for the image conversion, ensuring 100% compatibility with Vercel while keeping the serverless function lightweight and fast."
                  ],
                  "imageSrc": "/assets/blob-to-jpeg-solution.png"
                }
              ]
            },
            {
              "title": "2. Optimizing File Upload Workflow After Conversion",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "body": [
                    "Initially, I planned to upload the generated image to the WordPress Media API, since all student data was stored in WordPress. However, direct upload attempts from the Express server consistently failed due to CORS and authentication restrictions."
                  ]
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "I switched to Cloudinary, which provides a reliable and developer-friendly API for direct uploads. Using cloudinary.uploader.upload_stream(), I could efficiently upload the converted certificate image and receive a public URL for display. This allowed seamless integration with both the backend (phpMyAdmin) and frontend certificate page."
                  ],
                  "imageSrc": "/assets/process-upload-cloudinary.png"
                }
              ]
            },
            {
              "title": "3. Implementing Server-Side OG Tag Rendering for Facebook Previews",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "body": [
                    "While LinkedIn and X correctly displayed link previews, Facebook failed to render the certificate image. This occurred because the application is a Vue.js SPA, where Open Graph (OG) meta tags are injected client-side via JavaScript. Facebook's crawler does not execute JavaScript, meaning it only saw the initial empty HTML shell without the necessary metadata."
                  ]
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "I implemented a server-side rendering strategy for OG tags. I created a dedicated backend route (e.g., /api/certificates/share/:id) that generates and serves static HTML containing the pre-populated og:image, og:title, and og:description tags.",
                    "For Crawlers: When Facebook requests this URL, it receives static HTML with the correct Cloudinary image link instantly, allowing the preview to render.",
                    "For Users: Clicking the preview redirects the user to the actual interactive Vue application.",
                    "This approach bridged the gap between the serverless Vue frontend and legacy crawler behaviors without needing a full-scale SSR framework like Nuxt.js."
                  ],
                  "imageSrc": "/assets/facebook-og-preview.png"
                }
              ]
            }
          ]
        },
        "performance--accessibility": {
          "body": [
            "Optimized certificate generation to minimize image size without losing clarity.",
            "Ensured all interactive elements (buttons, QR, inputs) meet accessibility color-contrast and keyboard navigation standards."
          ]
        },
        "impact-reflection": {
          "body": [
            "This project deepened my understanding of compatibility between cloud platforms and libraries, especially regarding native binaries. I also gained hands-on experience in:",
            "Debugging style inheritance conflicts across frameworks.",
            "Managing multi-environment deployments (Vercel + Hostinger + WordPress data).",
            "Strengthening troubleshooting skills for complex full-stack integrations."
          ]
        },
        "testing--ci/cd": {
          "body": [
            "Implemented GitHub Actions for automated deployment and build checks.",
            "Server: Deployed via Vercel",
            "Client: Hosted on Hostinger",
            "Data: Fetched dynamically from existing WordPress datasets"
          ]
        },
        "next-steps": {
          "body": [
            "Evaluate backend-side libraries before deployment to ensure compatibility with the target cloud platform (e.g., AWS Lambda, Vercel).",
            "Explore image generation using serverless functions for better performance and reliability."
          ]
        },
        "key-learnings": {
          "body": [
            "Integrated WordPress data with a custom certificate platform.",
            "Learned how library behavior varies depending on the cloud platform environment.",
            "Strengthened practical understanding of frontend–backend–cloud interoperability."
          ]
        },
        "related-articles": {
          "body": [],
          "relatedPostsFromDevTo": true,
          "devToTag": "projectecertificate"
        }
      }
    },
    {
      "id": "college-cms",
      "type": "Web Platform",
      "title": "Web Platform & Custom Headless CMS",
      "technologies": [
        "React",
        "Next.js 15",
        "TypeScript",
        "Convex",
        "Tailwind CSS",
        "shadcn/ui",
        "Clerk",
        "Stripe",
        "Cloudinary",
        "Coolify"
      ],
      "year": "June, 2025",
      "role": "Full stack Developer",
      "member": "2 Developers",
      "demoUrl": "#",
      "sourceUrl": "#",
      "designUrl": "#",
      "hideLinks": true,
      "topImage": "/assets/college-cms-hero.png",
      "hiddenSections": ["Security", "Impact & Reflection"],
      "sections": {
        "process": {
          "body": [],
          "image": "/assets/college-cms-architecture.png",
          "imageTitle": "User Experience:",
          "imageBelowFirst": "/assets/college-cms-fullstack-overview.png",
          "imageBelowFirstTitle": "Development Workflow & CI/CD Pipeline"
        },
        "product-overview": {
          "image": "/assets/college-cms-hero.png",
          "body": [
            "Developed a unified web platform and an internal Headless CMS with real-time content synchronization.",
            "To address the limitations of the legacy system, I re-architected the entire platform using Next.js 15 and Convex (BaaS). I engineered a dynamic architecture utilizing Convex Cloud for real-time data synchronization, ensuring that content updates made in the admin dashboard are instantly reflected on the client-side without manual deployments."
          ]
        },
        "system-design": {
          "image": "/assets/college-cms-system-design.png",
          "heading": "Architecture & Data Flow Strategy",
          "body": [
            "Why Turborepo?",
            "To maintain high velocity in a monorepo environment, I integrated Turborepo as the underlying build system.",
            "Intelligent Caching (\"Never do the same work twice\"): Turborepo analyzes the dependency graph and caches the result of tasks (build, test, lint). If code hasn't changed, it skips execution and instantly restores the output from the cache, reducing local build times from minutes to milliseconds.",
            "Remote Caching: By sharing the cache artifacts across the team and CI/CD pipelines, the entire development lifecycle is accelerated. Once a commit is built in CI or by a team member, subsequent builds can retrieve the artifacts from the cloud, eliminating redundant processing.",
            "The platform is architected as a modern, custom Headless CMS within a Turborepo monorepo, leveraging Convex BaaS as the central nervous system for data and logic. This design ensures type safety, scalability, and a seamless developer experience across both applications.",
            "Admin App (CMS Content Entry): The administrative dashboard is secured by a Clerk Authentication Layer. Staff members interact with a user-friendly interface (built with shadcn/ui and TipTap) to manage content. Data updates are sent as secure, authenticated Mutations directly to Convex.",
            "Convex BaaS (The Single Source of Truth): Acting as the backend hub, Convex hosts the database, executes API functions, and manages integrations with external services like Cloudinary (media) and Stripe (payments). Its built-in Real-time Engine instantly pushes updates to subscribed clients.",
            "Web App (Public Content Delivery): The public-facing site employs a hybrid data-fetching strategy for optimal performance and SEO. It primarily uses Server-Side Fetching (with ISR) to render content fast and search-engine-friendly. For dynamic content requiring immediate updates, it utilizes real-time Subscriptions to reflect changes instantly from the Admin panel.",
            "Shared Infrastructure: Shared Packages for UI components, TypeScript types, and configurations are utilized by both apps to maintain consistency and accelerate development."
          ]
        },
        "constraints--trade-offs": {
          "body": [
            "Constraints: Since the primary CMS users are non-technical staff, a \"foolproof UI\" was essential. I designed strict form validations and preview features to prevent accidental errors, shielding users from SQL or raw code.",
            "Trade-offs: Regarding real-time data, I prioritized SEO and initial load speed (Core Web Vitals) for the public site by relying primarily on Server-Side Fetching (RSC) rather than full real-time synchronization, which is reserved for the Admin dashboard."
          ],
          "processBlocks": [
            {
              "title": "1. Migration from Legacy WordPress",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "body": [
                    "The previous WordPress system relied heavily on plugins and required risky PHP modifications for design updates. This created a fragility in the system where updates could break functionality, and performance/SEO was limited by the monolithic structure."
                  ]
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "I migrated the platform to Next.js, decoupling the frontend from the backend logic. This shift to a Headless architecture eliminated direct code editing risks for content, significantly boosted SEO via SSR, and allowed for scalable feature development without legacy constraints."
                  ]
                }
              ]
            },
            {
              "title": "2. Performance vs SEO Complexity",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "body": [
                    "For a content-rich homepage, standard SSR (Server-Side Rendering) ensures SEO but often leads to a heavy \"Main Thread\" during hydration, delaying the Largest Contentful Paint (LCP). Conversely, standard Client-Side Rendering (CSR) hurts search rankings."
                  ]
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "I implemented a \"Hybrid Hydration Strategy\" using next/dynamic. By strategically splitting the application into independent chunks, I kept the initial JavaScript bundle minimal while maintaining ssr: true for all SEO-critical sections. This ensured that search engines received fully rendered HTML, while the browser could prioritize rendering the visual \"Hero\" area without waiting for the entire page's logic. This architectural choice was a key factor in achieving a {{75% improvement in LCP}}."
                  ]
                }
              ]
            },
            {
              "title": "3. UX vs Data Integrity",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "body": [
                    "The administrative staff needed to manage complex data (programs, certificates) without technical knowledge. Giving them raw database access or a complex UI risked data corruption and operational errors."
                  ]
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "Built a custom Admin dashboard using shadcn/ui and TipTap that mirrors the mental model of the staff. Implemented strict form validation (Zod) and real-time previews, ensuring that \"what you see is what you get\" and preventing invalid data from ever reaching the production database."
                  ]
                }
              ]
            },
            {
              "title": "4. Real-time vs Performance",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "body": [
                    "The Admin dashboard required real-time synchronization for collaboration, whereas the Public site needed static-like speed and high SEO scores. Using client-side fetching everywhere would hurt SEO, while static generation would delay content updates."
                  ]
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "I leveraged Convex's real-time subscriptions for the Admin panel to ensure instant feedback. For the Public site, I utilized Next.js Server Actions and ISR, achieving excellent Core Web Vitals (LCP < 1.0s) while ensuring content updates are reflected within 60 seconds."
                  ]
                }
              ]
            },
            {
              "title": "5. Consistency in Development",
              "subsections": [
                {
                  "heading": "Challenge:",
                  "body": [
                    "Developing separate Web and Admin applications often leads to duplicated types and inconsistent UI components, increasing maintenance overhead and the risk of bugs during API communication."
                  ]
                },
                {
                  "heading": "Solution:",
                  "body": [
                    "Adopting Turborepo allowed me to share UI libraries and strict TypeScript schemas across apps. Combined with Convex, this provided end-to-end type safety—changing a database schema instantly updates types in both the Web and Admin frontends, eliminating integration bugs."
                  ]
                }
              ]
            }
          ]
        },
        "performance--accessibility": {
          "body": [
            "Performance: Optimized media delivery using Cloudinary and Next.js next/image. Minimized client bundle size by aggressively utilizing React Server Components.",
            "Accessibility: Built both the Admin and Public interfaces on shadcn/ui (Radix UI), ensuring full support for keyboard navigation and screen readers (ARIA attributes)."
          ]
        },
        "testing--ci/cd": {
          "body": [
            "Testing: Integrated Vitest to perform unit tests on core utility functions and redirect logic, ensuring system reliability.",
            "CI/CD: Established a pipeline using GitHub Actions to automate linting and testing on Pull Requests. Merges to the main branch trigger automatic deployment to Coolify."
          ]
        },
        "next-steps": {
          "body": [
            "Expand E2E Testing: Introduce Playwright to automate testing for critical paths, from Admin content creation to Public site rendering.",
            "Localization Workflow: Integrate AI translation APIs into the pipeline to auto-generate initial draft translations for the 5 supported languages.",
            "Analytics: Develop a feature to aggregate user behavior logs in Convex and visualize engagement metrics within the Admin dashboard."
          ]
        },
        "key-learnings": {
          "body": [
            "Power of End-to-End Type Safety: I experienced how the combination of Convex and TypeScript ensures automatic type propagation from the DB schema to the frontend, resulting in highly resilient code and significantly fewer bugs.",
            "Monorepo Operations: Sharing business logic and UI between the Web and Admin apps prevented inconsistency and accelerated the development velocity.",
            "CMS Design Philosophy: I learned that beyond technical features, crafting a \"user-friendly UI/UX\" for operators is the most critical factor in determining the long-term value and usability of the system."
          ]
        },
        "related-articles": {
          "body": [],
          "relatedPostsFromDevTo": true,
          "devToTag": "projectcollegecms"
        }
      }
    },
    {
      "id": "portfolio",
      "type": "Web site",
      "title": "Portfolio",
      "technologies": ["React", "TypeScript", "TailwindCSS"],
      "year": "January, 2026",
      "role": "Full stack Developer",
      "member": "1 Developer",
      "demoUrl": "https://atena-hatta.vercel.app/",
      "sourceUrl": "https://github.com/AtenaHatta/Portfolio_2026",
      "topImage": "/assets/portfolio-hero.png",
      "hiddenSections": ["Security", "Next Steps"],
      "sections": {
        "product-overview": {
          "body": [
            "I’ve redesigned and rebuilt theportfoli multiple times, and this is a version 4. In this version, I prioritized a accessible UI/UX and focused on clearly articulating my value. I drove this project end-to-end, from the conceptual design to the technical architecture, and I update the platform by user feedback."
          ],
          "image": "/assets/portfolio-hero.png"
        },
        "process": {
          "imageTitle": "End-to-End Project Lifecycle",
          "researchStrategy": {
            "phaseTitle": "Phase 1: Research & Strategy",
            "findings": [
              {
                "title": "Performance Expectation",
                "metric": "2 sec",
                "description": "less Load Time is expected for a positive first impression. Users decide whether to stay or leave in just 50 milliseconds.",
                "image": "/assets/portfolio-research-performance.webp"
              },
              {
                "title": "Prioritized Information",
                "metric": "80%",
                "description": "of recruiters look for 'Process & Problem Solving' over just 'Visuals'.",
                "image": "/assets/portfolio-research-prioritized.webp"
              },
              {
                "title": "Accessibility Standards",
                "metric": "1 in 6 people",
                "description": "(16% of the global population) experience significant disability. High contrast is a necessity.",
                "image": "/assets/portfolio-research-accessibility.webp"
              }
            ],
            "strategyTitle": "STRATEGY DEFINED",
            "strategyItems": [
              "Enforce strict performance budgets (LCP < 2s).",
              "Prioritize 'Process' documentation over art",
              "Adhere to WCAG standards for inclusivity."
            ]
          },
          "": [
            { "title": "Research", "items": ["Journey Mapping", "Research UI/UX"] },
            { "title": "Strategy", "items": ["System Design", "Tech stack"] },
            { "title": "Design", "items": ["Wireframes", "Mockups"] },
            { "title": "Development", "items": ["Coding"] },
            { "title": "Deployment", "items": ["Development", "CI/CD"] },
            { "title": "Testing", "items": ["QA Test", "Usability Testing", "Maintaine a PDCA"] }
          ],
          "body": [
            "This lifecycle was built not just to refine visuals, but to harmonize engineering feasibility with a seamless user experience. By handling everything from scratch-built wireframes to final implementation, I ensure that the original design intent is 100% embodied in the final product."
          ],
          "phase2Mockup": {
            "title": "Phase 2: Mockup Design",
            "body": "Implemented a high-contrast Dark Mode and established a unified Color System and Typography in Figma, ensuring visual consistency and efficient implementation.",
            "image": "/assets/portfolio-mockup-design.webp",
            "subtitle": "Components, Color system, Icons",
            "image2": "/assets/portfolio-design-color-system.webp"
          },
          "phase3TechStack": {
            "title": "Phase 3: Tech Stack",
            "items": [
              "Frontend: React, TypeScript, Vite, Tailwind CSS",
              "Component & quality: Storybook, Biome, Husky",
              "Assets: Sharp, WebP",
              "Deployment & CI/CD: Vercel",
              "External: Dev.to API"
            ]
          }
        },
        "system-design": {
          "architectureHighlights": {
            "image": "/assets/portfolio-dev-design-system.webp",
            "title": "Architecture Highlights:",
            "items": [
              "Pre-rendering Strategy: Decoupled external dependencies (Dev.to API) by fetching data and optimizing assets (Sharp/WebP) at build time.",
              "Optimized Delivery: Utilized Vite to inject non-blocking CSS and module preloads, ensuring a sub-second LCP.",
              "Quality Gates: Integrated Husky, Biome, and Storybook into the workflow to enforce strict code standards and UI consistency.",
              "Infrastructure: Deployed on Vercel's Edge Network with SPA rewrite rules for seamless client-side routing."
            ]
          }
        },
        "constraints--trade-offs": {
          "constraintTradeOffBlocks": [
            {
              "heading": "1. Achieving a perfect 99% LCP score",
              "body": [
                "I decided to minimize heavy JavaScript animations and large assets. Instead, I focused on CSS-based micro-interactions and optimized typography.",
                "Result: This prioritized immediate content delivery over visual excess, ensuring the best possible user retention."
              ]
            },
            {
              "heading": "2. Font loading — Layout Stability over Visual Uniformity",
              "body": [
                "To achieve a CLS (Cumulative Layout Shift) of 0, I transitioned from font-display: swap to optional and inlined the critical font CSS.",
                "- The Trade-off: I accepted the risk that users on extremely slow networks might see system fonts instead of \"JetBrains Mono\" (FOIT prevention).",
                "- The Gain: Eliminating the layout shift caused by font swapping, guaranteeing a rock-solid, jank-free visual experience for the majority of users."
              ]
            },
            {
              "heading": "3. Pre-rendering over Runtime Fetching",
              "body": [
                "Directly fetching articles from the Dev.to API caused unpredictable latency, negatively impacting LCP.",
                "- The Trade-off: I prioritized load speed over real-time data freshness. Instead of fetching data on every request (CSR/SSR), I implemented SSG (Static Site Generation).",
                "- The Gain: Decoupled the critical rendering path from external API response times, ensuring the article list loads instantly and stabilizing LCP at a high score."
              ]
            }
          ]
        },
        "performance--accessibility": {
          "performanceAccessibilityBlocks": [
            {
              "title": "Unlighthouse: Efficiency in Local Development",
              "body": [
                "Site-wide Auditing: Integrated Unlighthouse into the local development workflow to scan all routes simultaneously, enabling rapid identification of performance bottlenecks."
              ],
              "image": "/assets/portfolio-unlighthouse.webp"
            },
            {
              "title": "Lighthouse: Precision Performance Tuning",
              "body": [
                "Multi-Platform Excellence: Achieved a 99% Performance Score on both Mobile and Desktop through rigorous auditing and technical refinement.",
                "Surpassing Expectations: I pushed my site's performance well beyond these industry standards, achieving:",
                "LCP (Largest Contentful Paint): 0.4s (Desktop) / 1.7s (Mobile) — significantly faster than the 2s threshold.",
                "FCP (First Contentful Paint): 0.3s (Desktop) / 1.2s (Mobile) — ensuring nearly instantaneous visual feedback.",
                "Total Blocking Time (TBT): 0ms — achieving a perfectly fluid interaction experience with zero execution delay.",
                "Ultra-Low Latency: By eliminating render-blocking resources and optimizing asset delivery, I pushed the load time significantly below these thresholds—reaching millisecond-level response times to guarantee a seamless user experience.",
                "Strategic Technical Trade-off: I made a decision to leave the final 1% unaddressed, as it stems from external API constraints within the dev.to integration. I prioritized maintaining the dynamic integration with a reputable developer platform over a purely cosmetic \"100%\" score."
              ],
              "image": "/assets/portfolio-lighthouse.webp"
            }
          ]
        },
        "testing--ci/cd": {
          "testingCiCdBlock": {
            "title": "Storybook: Component-Driven Development",
            "body": [
              "Scalable UI Catalog: Centralized management of reusable components like Chip, Button, and ProjectCard.",
              "Theme & Interaction: Real-time validation for Light/Dark modes and dynamic prop testing using Storybook Controls.",
              "Production Fidelity: Integrated Tailwind CSS and production utilities (getColors) to ensure 100% visual consistency.",
              "Auto-Documentation: Leveraged autodocs to maintain clear UI specifications for seamless handovers and onboarding.",
              "Static Deployment: Deployed a public UI library via Vercel to demonstrate modular architecture and design system expertise."
            ],
            "image": "/assets/portfolio-storybook.webp"
          }
        },
        "impact--reflection": {
          "impactReflectionBlock": {
            "body": [
              "I treated this portfolio as a living product, applying a PDCA cycle to refine the user experience post-launch.",
              "- Qualitative Feedback (Professional Review): I actively sought critiques from Developers, Designers, and HR managers. Their diverse perspectives helped me optimize the code structure and refine the narrative to better align with hiring expectations.",
              "- Quantitative Data (User Behavior): I integrated Microsoft Clarity to analyze real user interaction. Heatmaps and session recordings revealed navigation patterns, which I used to eliminate friction points and improve content discoverability.",
              "- Agile Refinement (Rapid Action): Feedback was never ignored. I maintained a CI/CD pipeline that allowed me to deploy fixes and UX improvements immediately upon discovery."
            ],
            "image": "/assets/portfolio-pdca-cycle.webp"
          }
        },
        "key-learnings": {
          "body": [
            "Performance-focused development with Vite: Hands-on experience optimizing load speeds using plugins for async CSS and modulepreload.",
            "Static-Dynamic hybrid architecture: Learned to integrate the Dev.to API with custom build scripts to manage \"static site + external content\" configurations.",
            "Standardizing component and code quality: Established a consistent development workflow by implementing Storybook, Biome, and Husky.",
            "Practical asset optimization: Implemented font preloading and image processing (Sharp) to ensure a fast and polished user experience."
          ]
        }
      }
    }
  ],
  "detailSections": [
    "Product Overview",
    "Process",
    "System Design",
    "Constraints & Trade-offs",
    "Performance & Accessibility",
    "Testing & CI/CD",
    "Security",
    "Impact & Reflection",
    "Key Learnings",
    "Next Steps",
    "Related Articles"
  ]
}
